{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import os\n",
    "import sqlite3\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.document_loaders import UnstructuredCSVLoader\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "import tiktoken  # Para contar tokens\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-20T19:25:18.889522Z",
     "start_time": "2024-12-20T19:25:18.839686Z"
    }
   },
   "id": "ef047e68a57066df",
   "execution_count": 336
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "load_dotenv(find_dotenv())\n",
    "api_key = os.getenv(\"HUGGIN_FACE2\")\n",
    "\n",
    "# 2. Definir token e modelo\n",
    "HUGGINGFACEHUB_API_TOKEN = api_key\n",
    "MODEL_REPO_ID = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "MAX_TOKENS = 8192\n",
    "\n",
    "# 3. Template do prompt\n",
    "template = \"\"\" \n",
    "    Você é um assistente especializado em futebol, capaz de responder perguntas de maneira precisa e informada.\n",
    "    \n",
    "    É muito importante que você responda da forma mais direta possível, você nao pode dar informações nas quais nao foram solicitados.\n",
    "    Você precisa consultar os dados disponibilizados em {data}.\n",
    "    Você não pode incluir códigos, a menos que seja pedido. \n",
    "\n",
    "    Lembrando que você tem todos os dados sobre o campeonato inglês (Premier League) e os dados junto dos significados das siglas que você tem à disposição estão dentro do arquivo {combined_info}.  \n",
    "    \n",
    "    Contexto:\n",
    "    - Banco de dados: contém dados atualizados sobre jogadores, times, estatísticas e competições.\n",
    "    - {combined_info}: inclui o glossário sobre siglas das colunas presentes nos dados.\n",
    "    \n",
    "    Arquivos com as estatísticas: {data}.\n",
    "    Informações adicionais: {combined_info}.\n",
    "    \n",
    "    Pergunta do usuário: {question}\n",
    "    \n",
    "    Resposta:\n",
    "    \"\"\"\n",
    "\n",
    "# 4. Função para carregar informações de arquivos\n",
    "def load_info(file_paths):\n",
    "    combined_content = \"\"\n",
    "    for file in file_paths:\n",
    "        with open(file, 'r', encoding='utf-8') as f:\n",
    "            combined_content += f.read() + \"\\n\"\n",
    "    return combined_content\n",
    "\n",
    "# 5. Carregar glossário e dados CSV\n",
    "combined_info = load_info(file_paths=[\n",
    "    r'C:\\Users\\Wellbe\\DataspellProjects\\dsProject\\football_api\\files\\infos\\glossary.txt'\n",
    "])\n",
    "\n",
    "loader = CSVLoader(\n",
    "    file_path=r'C:\\Users\\Wellbe\\DataspellProjects\\dsProject\\football_api\\files\\2024-12-20\\data_info_pl.csv',\n",
    "    encoding='latin1'\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "# 6. Dividir os dados em partes menores\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "\n",
    "# 7. Calcular tokens e garantir que fiquem dentro do limite\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "valid_chunks = []\n",
    "for doc in split_docs:\n",
    "    num_tokens = len(tokenizer.encode(doc.page_content))\n",
    "    if num_tokens + 256 <= MAX_TOKENS:  # Garante que entrada + saída não ultrapassem 8192\n",
    "        valid_chunks.append(doc)\n",
    "\n",
    "# 8. Criar embeddings e indexar os documentos\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vector_store = FAISS.from_documents(valid_chunks, embedding_model)\n",
    "\n",
    "# 9. Função para recuperar documentos relevantes\n",
    "def retrieve_relevant_docs(question, top_k=3):\n",
    "    return vector_store.similarity_search(question, top_k)\n",
    "\n",
    "# 10. Configuração do modelo com HuggingFaceEndpoint\n",
    "llm = HuggingFaceEndpoint(\n",
    "    endpoint_url=f\"https://api-inference.huggingface.co/models/{MODEL_REPO_ID}\",\n",
    "    huggingfacehub_api_token=HUGGINGFACEHUB_API_TOKEN,\n",
    "    temperature=0.2,\n",
    "    max_new_tokens=512\n",
    ")\n",
    "\n",
    "# 11. Função para gerar respostas com RAG\n",
    "def generate_answer(question):\n",
    "    # Recuperar documentos relevantes\n",
    "    relevant_docs = retrieve_relevant_docs(question)\n",
    "    context = \"\\n\".join([doc.page_content for doc in relevant_docs])\n",
    "\n",
    "    # Criar o prompt com as informações recuperadas\n",
    "    prompt = PromptTemplate(\n",
    "        template=template,\n",
    "        input_variables=['question', 'data', 'combined_info']\n",
    "    )\n",
    "    prompt_with_context = prompt.format(\n",
    "        question=question,\n",
    "        data=context,\n",
    "        combined_info=combined_info\n",
    "    )\n",
    "\n",
    "    # Gerar a resposta usando o LLM\n",
    "    response = llm.invoke(prompt_with_context)\n",
    "    return response\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-20T19:33:53.566962Z",
     "start_time": "2024-12-20T19:32:52.537135Z"
    }
   },
   "id": "675fa7725f22472",
   "execution_count": 345
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Based on the provided data, the following Chelsea players are available in the database:\n",
      "\n",
      "    1. Moisés Caicedo (ECU, MF/DF, Age: 23)\n",
      "    2. Tosin Adarabioyo (ENG, DF, Age: 27)\n",
      "    3. João Félix (POR, FW/MF, Age: 25)\n",
      "\n",
      "    These players have all appeared in the Premier League matches for Chelsea and their statistics are available in the database.\n"
     ]
    }
   ],
   "source": [
    "# 12. Testar o pipeline com uma pergunta\n",
    "question = \"Me faça uma lista dos jogadores do chelsea disponiveis na base de dados?\"\n",
    "answer = generate_answer(question)\n",
    "print(answer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-20T19:33:57.721065Z",
     "start_time": "2024-12-20T19:33:53.585471Z"
    }
   },
   "id": "e17340517d262731",
   "execution_count": 346
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Pergunta sobre estatísticas de futebol\n",
    "#question = \"Me faça uma lista dos times disponiveis na base de dados?\"\n",
    "#question = \"Me faça uma lista dos jogadores do chelsea disponiveis na base de dados?\"\n",
    "question = \"Qual jogador do chelsea com mais gols?\"\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-20T19:22:02.824207Z",
     "start_time": "2024-12-20T19:22:02.819558Z"
    }
   },
   "id": "bb89a30bea7b9d2a",
   "execution_count": 332
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
